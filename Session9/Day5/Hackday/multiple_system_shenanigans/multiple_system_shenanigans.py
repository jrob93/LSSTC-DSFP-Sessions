'''
investigate multiplicity of systems. Uses dfs generated by plot_binary_evolution.py
'''
from matplotlib import rc
rc('font',**{'size':9})

import pandas as pd
import numpy
import py_func as pf
import matplotlib.pyplot as pyplot
import matplotlib.gridspec as gridspec
import matplotlib.colors
import os
import glob
import networkx as nx

graph_plot=0
orb_plot=1

# Load the dfs
path="/Users/jrobinson/xq1_grav_cloud/binary_stability/orbit_results/orbit_results_plots"
dat_path="/Users/jrobinson/cloud_runs_data/data/jakita_raid2/jer/grav_cloud"
restart_path="/Users/jrobinson/xq1_grav_cloud/binary_stability/cloud_runs_helio/restart_dirs_N100_f1"

df_plot_all=pd.read_csv("{}/df_plot_100_all.txt".format(path),sep="\t",index_col=0)
df_plot_all_stable=pd.read_csv("{}/df_plot_100_all_stable.txt".format(path),sep="\t",index_col=0)

# df_plot_all=df_plot_all[df_plot_all["N_sys"]>1]
df_plot_all_stable=df_plot_all_stable[df_plot_all_stable["N_sys"]>1]

# print df_plot_all
print df_plot_all_stable
print numpy.unique(df_plot_all_stable['run']),len(numpy.unique(df_plot_all_stable['run']))

# multiple systems
N_mult=[3,4]
for N in N_mult:
    df_mult=df_plot_all_stable[df_plot_all_stable['N_sys']==N]
    print df_mult[['run','R_eq(m)','f','X','i_orig','m1(kg)','m2(kg)','N_sys']]

    # load the collision file
    for i in range(len(df_mult)):
        r_split=df_mult.iloc[i]['run_dir'].split("/")
        run=r_split[-1]
        set=r_split[-2]
        pri=df_mult.iloc[i]['i_orig']
        print set,run,pri

        orb_file="{}/{}_{}_{}/{}_{}_{}_orbit_search_faster_hel.txt".format(restart_path,run,set,int(pri),run,set,int(pri))
        df_orb=pf.load_orb_file(orb_file)
        # print df_orb
        df=df_orb[df_orb['t(s)']==numpy.amax(df_orb['t(s)'])]

        #laod run params
        data_path="{}/{}/{}".format(dat_path,set,run)
        files=next(os.walk(data_path))[2] #retrieve the files in the run directory
        files.sort() #ensure that the files are always sorted the same?
        rp_files = [ fi for fi in files if fi.endswith(".txt") and fi.startswith("run_params") ]
        df_rp=pf.load_run_params("{}/{}".format(data_path,rp_files[-1]))

        # load last restarted data file
        restart_dir="{}/{}_{}_{}".format(restart_path,run,set,int(pri))
        list_of_files = glob.glob("{}/*".format(restart_dir))
        dat_file_list=[f for f in list_of_files if "dat" in f and f.endswith(".txt")]
        dat_file_list.sort()
        latest_dat_file = dat_file_list[-1]

        df=pf.create_df_tot(run,df,df_rp,latest_dat_file) # use original df_rp
        df=pf.binary_selector(df)
        print df[['run','i','j','m1(kg)','m2(kg)','m2/m1']],len(df)

        if graph_plot==1:
            # Make a networkx graph
            df = df.astype({"i": int,"j": int}) #convert dataframe i and j to integers
            G=nx.from_pandas_edgelist(df, source='i', target='j') # Build your graph from dataframe

            # Set node sizes by the particle mass
            node_inds=list(G.nodes) #list of all nodes (i.e. every unique occurrence of particle i and j)
            mass=[]
            for n in node_inds:
                # find the masses of i and j as particle n could be either a primary or a secondary
                m_pri=numpy.unique(numpy.array(df[df['i']==n]['m1(kg)']).astype(float))
                m_sec=numpy.unique(numpy.array(df[df['j']==n]['m2(kg)']).astype(float))
                if len(m_pri)==1: # particle n is a primary i
                    mass.append(m_pri[0])
                elif len(m_sec)==1: # particle n is a secondary j
                    mass.append(m_sec[0])
                else:
                    print "no masses? ERROR"
                    exit()
            # node_sizes=(mass) # unaltered mass scale
            node_sizes=numpy.log10(mass) #use a log scale for mass?
            #rescale the sizes so that the smallest mass has size: size_min, and the largest has size: size_max
            size_max=500
            size_min=30
            node_sizes-=numpy.amin(node_sizes) # rescale to start at zero
            if node_sizes.max()!=0.0: #deals with case were all particles are the same mass
                node_sizes *= ((size_max-size_min)/node_sizes.max()) # stretch to end at size_max-size_min
            node_sizes+=size_min # shift up by size_min

            # check for multiple systems
            primary_nodes=[]
            secondary_nodes=[]
            graphs = list(nx.connected_component_subgraphs(G)) # find all unconnected node systems
            for _G in graphs:
                _secondary_nodes=[]

                # assess some system properties
                N_edges= _G.number_of_edges() # total number of orbits
                _node_inds=list(_G.nodes) # the list of nodes (particles) in the system
                _loops_list=numpy.array(nx.cycle_basis(_G)) # find any closed loops

                # Select the primary node by mass
                _df=df[numpy.isin(df['i'],_node_inds)].sort_values(by=['m1(kg)','m2(kg)'],ascending=False)
                node_most_massive=int(_df['i'].iloc[0])
                primary_nodes.append(node_most_massive)

                # use the degree of each node to find secondaries
                for n in _node_inds:
                    # print n,_G.degree(n),list(_G[n].keys())#G.neighbors(n)
                    if _G.degree(n)>1:
                        if n not in primary_nodes:
                            secondary_nodes.append(n) # secondary nodes for whole run (graph G)
                            _secondary_nodes.append(n) #secondary node for this one system (graph _G)

                # the longest path between nodes is a good measure of system complexity
                path_lengths=[]
                for n in _node_inds:
                    # check all path lengths
                    if n!=node_most_massive:
                        paths=list(nx.all_simple_paths(G, node_most_massive, n))
                        # print "paths, number of paths = ",paths,len(paths)
                        for p in paths:
                            path_lengths.append(len(p))
                            # print "number of edges in path: ",len(p)
                longest_path=numpy.amax(path_lengths)


            # find the closed loops, these may be a circumbinary system, or an unstable system
            loops_list=numpy.array(nx.cycle_basis(G))
            # print "closed nodes: ",loops_list

            # set the node colours according to binary class
            color=[]
            for n in node_inds:
                if n in primary_nodes: # the most massive particle in a system
                    # print n," primary"
                    color.append('b')
                elif n in secondary_nodes: # a particle that has a secondary, when itself is also a secondary
                    if n in loops_list: # this particle feels the gravitaitonal influence of two other particles, could be circumbinary or unstable?
                        # print n," circumbinary?"
                        color.append('y')
                    else:
                        # print n," nested"
                        color.append('g')
                else: # all other particles, only has one primary
                    # print n," other"
                    color.append('r')

            # create the graph
            nx.draw(G, with_labels=True,node_size = node_sizes,node_color = color)

            #save the figure
            script_name=os.path.basename(__file__).split('.')[0]
            picname="{}_{}_{}_N{}.png".format(script_name,run,int(pri),N)
            print "save {}".format(picname)

            pyplot.savefig(picname,bbox_inches='tight',pad_inches=0.0)
            # pyplot.show()
            pyplot.close()
            # exit()

        if orb_plot==1:
            # create figure
            fig = pyplot.figure()
            gs = gridspec.GridSpec(1,1)
            ax1 = pyplot.subplot(gs[0,0])
            ax1.set_aspect("equal")

            # Plot the orbit
            marker_size=50

            pri_pos=numpy.array(df[['x1(m)','y1(m)','y1(m)']])
            sec_pos=numpy.array(df[['x2(m)','y2(m)','y2(m)']])
            m_pri=numpy.array(df['m1(kg)'])
            m_sec=numpy.array(df['m2(kg)'])
            pri_list=numpy.array(df['i']).astype(int)
            sec_list=numpy.array(df['j']).astype(int)

            for j in range(len(df)):

                orb=numpy.array(df.iloc[j][['a(m)','e','I(rad)','OMEGA(rad)','omega(rad)']])
                pos_orb=pf.planet_orbit(orb,100)

                # Marker size is set relative to the main primary
                m_size=marker_size*((m_pri[j])/(m_pri[0]))**(1.0/2.0)
                print m_size
                ax1.scatter(pri_pos[j,0],pri_pos[j,1],s=m_size,zorder=1)

                m_size=marker_size*((m_sec[j])/(m_pri[0]))**(1.0/2.0)
                print m_size
                ax1.scatter(sec_pos[j,0],sec_pos[j,1],s=m_size,zorder=2)
                ax1.plot(pos_orb[:,0]+pri_pos[j,0],pos_orb[:,1]+pri_pos[j,1],zorder=0)

            # for _i in range(len(pri_pos)):
            #     # m_size=marker_size*(numpy.log10(m_pri[_i])/numpy.log10(m_pri[0]))**3.0
            #     m_size=marker_size*((m_pri[_i])/(m_pri[0]))**2.0
            #     print m_size
            #     ax1.scatter(pri_pos[_i,0],pri_pos[_i,1],s=m_size,zorder=1)
            #
            #     for j in range(len(sec_pos)):
            #         orb=numpy.array(df.iloc[j][['a(m)','e','I(rad)','OMEGA(rad)','omega(rad)']])
            #         pos_orb=pf.planet_orbit(orb,100)
            #         # m_size=marker_size*(numpy.log10(m_sec[j])/numpy.log10(m_pri[0]))**3.0
            #         m_size=marker_size*((m_sec[j])/(m_pri[0]))**2.0
            #         print m_size
            #         ax1.scatter(sec_pos[j,0],sec_pos[j,1],s=m_size,zorder=2)
            #         ax1.plot(pos_orb[:,0]+pri_pos[_i,0],pos_orb[:,1]+pri_pos[_i,1],zorder=0)

            # Reset the limits to be square
            xlims=ax1.get_xlim()
            ylims=ax1.get_ylim()
            xdiff=numpy.absolute(xlims[1]-xlims[0])
            ydiff=numpy.absolute(ylims[1]-ylims[0])
            if xdiff>ydiff:
                ydiff_mid=ylims[0]+(ydiff/2.0)
                ax1.set_ylim(ydiff_mid-(xdiff/2.0),ydiff_mid+(xdiff/2.0))
            else:
                xdiff_mid=xlims[0]+(xdiff/2.0)
                ax1.set_xlim(xdiff_mid-(ydiff/2.0),xdiff_mid+(ydiff/2.0))

            #save the figure
            script_name=os.path.basename(__file__).split('.')[0]
            picname="{}_{}_{}_orb{}.png".format(script_name,run,int(pri),N)
            print "save {}".format(picname)

            pyplot.savefig(picname,bbox_inches='tight',pad_inches=0.0)
            # pyplot.show()
            pyplot.close()
            # exit()

    #     break
    # break
